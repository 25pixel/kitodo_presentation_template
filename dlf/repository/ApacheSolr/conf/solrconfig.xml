<?xml version="1.0" encoding="UTF-8" ?>
<!--
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

		http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<!--
Changelog:

		2010-12-24 - Sebastian Meyer <sebastian.meyer@slub-dresden.de>
			Initial configuration for the DLF application.
-->
<!--
		For more details about configurations options that may appear in this
		file, see http://wiki.apache.org/solr/SolrConfigXml.

		Specifically, the Solr Config can support XInclude, which may make it easier to manage
		the configuration.  See https://issues.apache.org/jira/browse/SOLR-1167
-->
<config>
	<!--
		Set this to "false" if you want Solr to continue working even if there
		is an error in your configuration.
		You may want to set this to "false" in a production environment, but to
		"true" for testing purposes.
	-->
	<abortOnConfigurationError>${solr.abortOnConfigurationError:false}</abortOnConfigurationError>

	<!--
		Here you should mention all directories containing plugin files, which
		are used in solrconfig.xml or schema.xml. Everything contained in the
		optional "./lib" directory under the Solr home path is always included,
		so the following is just an example which does not make any sense.
		If you are using Solr only in conjunction with DLF you can leave this
		unchanged because you will not need any other than the standard plugins.
	-->
	<!-- <lib dir="./lib" /> -->

	<!--
		Specify the directory where Lucene should save its index files. Please
		notice that using a NFS mount here is possible but not recommended!
	-->
	<dataDir>${solr.core.dataDir}</dataDir>

	<indexDefaults>
		<!--
			Set this to "false" if you want Lucene to split the index in multiple
			files. Updating will be slightly faster, but searching a bit slower.
		-->
		<useCompoundFile>true</useCompoundFile>

		<!--
			Specify the allowed number of index segments before segments are merged
			together. Higher values will result in faster indexing and less system
			load, but slower searches.
		-->
		<mergeFactor>15</mergeFactor>

		<!--
			Specify how many documents or memory should be buffered before the data
			is written to a segment file. Whatever limit is reached first will result
			in a flush.
		-->
		<maxBufferedDocs>500</maxBufferedDocs>
		<ramBufferSizeMB>64</ramBufferSizeMB>

		<!--
			Specify how many documents may be in one segment and how many tokens may
			be in one field. The latter should not be too low because excess tokens
			will be discarded.
		-->
		<maxMergeDocs>2147483647</maxMergeDocs>
		<maxFieldLength>10000</maxFieldLength>

		<!-- Specify the timeouts for writing to the index and commiting changes. -->
		<writeLockTimeout>1000</writeLockTimeout>
		<commitLockTimeout>10000</commitLockTimeout>

		<!--
			Set this to "true" if you want to enable auto-commiting. This is not
			recommended as it significally slows indexing speed.
		-->
		<luceneAutoCommit>false</luceneAutoCommit>

		<!--
			Specify how Lucene should merge index segments. The given values are
			Lucene's standard since version 2.3, so just leave this unchanged as long
			as you do not need backwards compatibility for some reasons.
		-->
		<mergePolicy class="org.apache.lucene.index.LogByteSizeMergePolicy" />
		<mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler" />

		<!--
			Specify which file locking mechanism Lucene should use. The options are:
			single = use no file locking at all (not recommended!)
			native = use the system's standard locking method
			simple = use a plain file for locking
		-->
		<lockType>native</lockType>
	</indexDefaults>

	<!-- Here you can override some default settings from above for a specific index. -->
	<mainIndex>
		<!--
			If true, unlock any held write or commit locks on startup.
			This defeats the locking mechanism that allows multiple
			processes to safely access a lucene index, and should be
			used with care.
			This is not needed if lock type is 'none' or 'single'
		-->
		<unlockOnStartup>false</unlockOnStartup>

		<!--
			If true, IndexReaders will be reopened (often more efficient) instead
			of closed and then opened.
		-->
		<reopenReaders>true</reopenReaders>

		<!-- Here you can change the deletion policy. This should be left unchanged! -->
		<deletionPolicy class="solr.SolrDeletionPolicy">
			<str name="maxCommitsToKeep">1</str>
			<str name="maxOptimizedCommitsToKeep">0</str>
			<!-- <str name="maxCommitAge">30MINUTES</str> -->
			<!-- <str name="maxCommitAge">1DAY</str> -->
		</deletionPolicy>

		<!--
			To aid in advanced debugging, you may turn on IndexWriter debug logging.
			Setting to true will set the file that the underlying Lucene IndexWriter
			will write its debug infostream to.
		-->
		<infoStream file="INFOSTREAM.txt">false</infoStream>
	</mainIndex>

	<!--
		Enables JMX if and only if an existing MBeanServer is found, use this
		if you want to configure JMX through JVM parameters. Remove this to disable
		exposing Solr configuration and statistics to JMX.

		If you want to connect to a particular server, specify the agentId
		e.g. <jmx agentId="myAgent" />

		If you want to start a new MBeanServer, specify the serviceUrl
		e.g <jmx serviceUrl="service:jmx:rmi:///jndi/rmi://localhost:9999/solr"/>

		For more details see http://wiki.apache.org/solr/SolrJmx
	-->
	<jmx />

	<updateHandler class="solr.DirectUpdateHandler2">
		<!--
			Perform a <commit/> automatically under certain conditions:
			maxDocs - number of updates since last commit is greater than this
			maxTime - oldest uncommited update (in ms) is this long ago
			Instead of enabling autoCommit, consider using "commitWithin"
			when adding documents. http://wiki.apache.org/solr/UpdateXmlMessages
		-->
		<!-- <autoCommit>
			<maxDocs>10000</maxDocs>
			<maxTime>1000</maxTime>
		</autoCommit> -->

		<!--
			The RunExecutableListener executes an external command from a
			hook such as postCommit or postOptimize.
			exe - the name of the executable to run
			dir - dir to use as the current working directory. default="."
			wait - the calling thread waits until the executable returns. default="true"
			args - the arguments to pass to the program.  default=nothing
			env - environment variables to set.  default=nothing
		-->
		<!-- A postCommit event is fired after every commit or optimize command. -->
		<!-- <listener event="postCommit" class="solr.RunExecutableListener">
			<str name="exe">solr/bin/snapshooter</str>
			<str name="dir">.</str>
			<bool name="wait">true</bool>
			<arr name="args"><str>arg1</str><str>arg2</str></arr>
			<arr name="env"> <str>MYVAR=val1</str> </arr>
		</listener> -->

		<!-- A postOptimize event is fired only after every optimize command. -->
		<!-- <listener event="postOptimize" class="solr.RunExecutableListener">
			<str name="exe">snapshooter</str>
			<str name="dir">solr/bin</str>
			<bool name="wait">true</bool>
		</listener> -->
	</updateHandler>

	<query>
		<!--
			Maximum number of clauses in a boolean query... in the past, this affected
			range or prefix queries that expanded to big boolean queries - built in Solr
			query parsers no longer create queries with this limitation.
			An exception is thrown if exceeded.
		-->
		<maxBooleanClauses>1024</maxBooleanClauses>

		<!--
			Cache used by SolrIndexSearcher for filters (DocSets),
			unordered sets of *all* documents that match a query.
			When a new searcher is opened, its caches may be prepopulated
			or "autowarmed" using data from caches in the old searcher.
			autowarmCount is the number of items to prepopulate.  For LRUCache,
			the autowarmed items will be the most recently accessed items.
			Parameters:
			class - the SolrCache implementation LRUCache or FastLRUCache
			size - the maximum number of entries in the cache
			initialSize - the initial capacity (number of entries) of the cache.
			autowarmCount - the number of entries to prepopulate from and old cache.
		-->
		<filterCache class="solr.FastLRUCache" size="512" initialSize="512" autowarmCount="0" />

		<!--
			queryResultCache caches results of searches - ordered lists of
			document ids (DocList) based on a query, a sort, and the range
			of documents requested.
		-->
		<queryResultCache class="solr.LRUCache" size="512" initialSize="512" autowarmCount="0" />

		<!--
			documentCache caches Lucene Document objects (the stored fields for each document).
			Since Lucene internal document ids are transient, this cache will not be autowarmed.
		-->
		<documentCache class="solr.LRUCache" size="512" initialSize="512" autowarmCount="0" />

		<!--
			If true, stored fields that are not requested will be loaded lazily.
			This can result in a significant speed improvement if the usual case is to
			not load all stored fields, especially if the skipped fields are large compressed text fields.
		-->
		<enableLazyFieldLoading>true</enableLazyFieldLoading>

		<!--
			An optimization that attempts to use a filter to satisfy a search.
			If the requested sort does not include score, then the filterCache
			will be checked for a filter matching the query. If found, the filter
			will be used as the source of document ids, and then the sort will be
			applied to that.
		-->
		<useFilterForSortedQuery>true</useFilterForSortedQuery>

		<!--
			An optimization for use with the queryResultCache.  When a search
			is requested, a superset of the requested number of document ids
			are collected.  For example, if a search for a particular query
			requests matching documents 10 through 19, and queryWindowSize is 50,
			then documents 0 through 49 will be collected and cached.  Any further
			requests in that range can be satisfied via the cache.
		-->
		<queryResultWindowSize>20</queryResultWindowSize>

		<!--
			Maximum number of documents to cache for any entry in the queryResultCache.
		-->
		<queryResultMaxDocsCached>500</queryResultMaxDocsCached>

		<!--
			QuerySenderListener takes an array of NamedList and executes a
			local query request for each NamedList in sequence.
		-->
		<listener event="newSearcher" class="solr.QuerySenderListener">
			<arr name="queries">
				<!--
				<lst><str name="q">solr</str><str name="start">0</str><str name="rows">10</str></lst>
				<lst><str name="q">rocks</str><str name="start">0</str><str name="rows">10</str></lst>
				<lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
				-->
			</arr>
		</listener>

		<listener event="firstSearcher" class="solr.QuerySenderListener">
			<arr name="queries">
				<!--
				<lst><str name="q">solr rocks</str><str name="start">0</str><str name="rows">10</str></lst>
				<lst><str name="q">static firstSearcher warming query from solrconfig.xml</str></lst>
				-->
			</arr>
		</listener>

		<useColdSearcher>true</useColdSearcher>

		<maxWarmingSearchers>10</maxWarmingSearchers>
	</query>

	<!--
		Let the dispatch filter handler /select?qt=XXX
		handleSelect=true will use consistent error handling for /select and /update
		handleSelect=false will use solr1.1 style error formatting
	-->
	<requestDispatcher handleSelect="true" >
		<!--Make sure your system has some authentication before enabling remote streaming!  -->
		<requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048000" />

		<httpCaching lastModifiedFrom="dirLastMod" etagSeed="Solr">
			<cacheControl>max-age=30, public</cacheControl>
		</httpCaching>
	</requestDispatcher>

	<!--
		requestHandler plugins... incoming queries will be dispatched to the
		correct handler based on the path or the qt (query type) param.
		Names starting with a '/' are accessed with a path equal to the
		registered name.  Names without a leading '/' are accessed with:
		http://host/app/select?qt=name
		If no qt is defined, the requestHandler that declares default="true"
		will be used.
	-->
	<requestHandler name="standard" class="solr.SearchHandler" default="true">
		<!-- default values for query parameters -->
		<lst name="defaults">
			<str name="echoParams">explicit</str>
		</lst>
	</requestHandler>

	<!--
		DisMaxRequestHandler allows easy searching across multiple fields
		for simple user-entered phrases.  It's implementation is now
		just the standard SearchHandler with a default query type
		of "dismax".
		see http://wiki.apache.org/solr/DisMaxRequestHandler
	-->
	<requestHandler name="dismax" class="solr.SearchHandler" >
		<lst name="defaults">
			<str name="defType">dismax</str>
			<str name="echoParams">explicit</str>
			<float name="tie">0.01</float>
			<str name="qf">text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0 manu^1.1 cat^1.4</str>
			<str name="pf">text^0.2 features^1.1 name^1.5 manu^1.4 manu_exact^1.9</str>
			<str name="bf">popularity^0.5 recip(price,1,1000,1000)^0.3</str>
			<str name="fl">id,name,price,score</str>
			<str name="mm">2&lt;-1 5&lt;-2 6&lt;90%</str>
			<int name="ps">100</int>
			<str name="q.alt">*:*</str>
			<!-- example highlighter config, enable per-query with hl=true -->
			<str name="hl.fl">text features name</str>
			<!-- for this field, we want no fragmenting, just highlighting -->
			<str name="f.name.hl.fragsize">0</str>
			<!-- instructs Solr to return the field itself if no query terms are found -->
			<str name="f.name.hl.alternateField">name</str>
			<!-- defined below -->
			<str name="f.text.hl.fragmenter">regex</str>
		</lst>
	</requestHandler>

	<!--
		Note how you can register the same handler multiple times with
		different names (and different init parameters)
		This is just an example which is not used by DLF!
	-->
	<requestHandler name="partitioned" class="solr.SearchHandler" >
		<lst name="defaults">
			<str name="defType">dismax</str>
			<str name="echoParams">explicit</str>
			<str name="qf">text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0</str>
			<str name="mm">2&lt;-1 5&lt;-2 6&lt;90%</str>
			<!--
				This is an example of using Date Math to specify a constantly
				moving date range in a config...
			-->
			<str name="bq">incubationdate_dt:[* TO NOW/DAY-1MONTH]^2.2</str>
		</lst>
		<!--
			In addition to defaults, "appends" params can be specified
			to identify values which should be appended to the list of
			multi-val params from the query (or the existing "defaults").
			In this example, the param "fq=instock:true" will be appended to
			any query time fq params the user may specify, as a mechanism for
			partitioning the index, independent of any user selected filtering
			that may also be desired (perhaps as a result of faceted searching).

			NOTE: there is *absolutely* nothing a client can do to prevent these
			"appends" values from being used, so don't use this mechanism unless
			you are sure you always want it.
		-->
		<lst name="appends">
			<str name="fq">inStock:true</str>
		</lst>
		<!--
			"invariants" are a way of letting the Solr maintainer lock down
			the options available to Solr clients.  Any params values specified
			here are used regardless of what values may be specified in either
			the query, the "defaults", or the "appends" params.
			In this example, the facet.field and facet.query params are fixed,
			limiting the facets clients can use.  Faceting is not turned on by
			default - but if the client does specify facet=true in the request,
			these are the only facets they will be able to see counts for;
			regardless of what other facet.field or facet.query params they
			may specify.

			NOTE: there is *absolutely* nothing a client can do to prevent these
			"invariants" values from being used, so don't use this mechanism
			unless you are sure you always want it.
		-->
		<lst name="invariants">
			<str name="facet.field">cat</str>
			<str name="facet.field">manu_exact</str>
			<str name="facet.query">price:[* TO 500]</str>
			<str name="facet.query">price:[500 TO *]</str>
		</lst>
	</requestHandler>

	<!--
		a search component that enables you to configure the top results for
		a given query regardless of the normal lucene scoring.
	-->
	<searchComponent name="elevator" class="solr.QueryElevationComponent" >
		<!-- pick a fieldType to analyze queries -->
		<str name="queryFieldType">string</str>
		<str name="config-file">elevate.xml</str>
	</searchComponent>

	<!-- a request handler utilizing the elevator component -->
	<requestHandler name="/elevate" class="solr.SearchHandler" startup="lazy">
		<lst name="defaults">
			<str name="echoParams">explicit</str>
		</lst>
		<arr name="last-components">
			<str>elevator</str>
		</arr>
	</requestHandler>

	<!--
		Update request handler.

		Note: Since solr1.1 requestHandlers requires a valid content type header if posted in
		the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
		The response format differs from solr1.1 formatting and returns a standard error code.
		To enable solr1.1 behavior, remove the /update handler or change its path
	-->
	<requestHandler name="/update" class="solr.XmlUpdateRequestHandler" />

	<requestHandler name="/update/javabin" class="solr.BinaryUpdateRequestHandler" />

	<!-- CSV update handler, loaded on demand -->
	<requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy" />

	<requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />

	<!-- ping/healthcheck -->
	<requestHandler name="/admin/ping" class="PingRequestHandler">
		<lst name="defaults">
			<str name="qt">standard</str>
			<str name="q">solrpingquery</str>
			<str name="echoParams">all</str>
		</lst>
	</requestHandler>

	<highlighting>
		<!-- Configure the standard fragmenter -->
		<fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
			<lst name="defaults">
				<int name="hl.fragsize">100</int>
			</lst>
		</fragmenter>

		<!-- A regular-expression-based fragmenter (f.i., for sentence extraction) -->
		<fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
			<lst name="defaults">
				<!-- slightly smaller fragsizes work better because of slop -->
				<int name="hl.fragsize">70</int>
				<!-- allow 50% slop on fragment sizes -->
				<float name="hl.regex.slop">0.5</float>
				<!-- a basic sentence pattern -->
				<str name="hl.regex.pattern">[-\w ,/\n\"']{20,200}</str>
			</lst>
		</fragmenter>

		<!-- Configure the standard formatter -->
		<formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
			<lst name="defaults">
				<str name="hl.simple.pre"><![CDATA[<span class="sword">]]></str>
				<str name="hl.simple.post"><![CDATA[</span>]]></str>
			</lst>
		</formatter>
	</highlighting>

	<!--
		XSLT response writer transforms the XML output by any xslt file found
		in Solr's conf/xslt directory. Changes to xslt files are checked for
		every xsltCacheLifetimeSeconds.
	-->
	<queryResponseWriter name="xslt" class="org.apache.solr.request.XSLTResponseWriter">
		<int name="xsltCacheLifetimeSeconds">86400</int>
	</queryResponseWriter>

	<!-- config for the admin interface -->
	<admin>
		<defaultQuery>DLF</defaultQuery>
	</admin>

</config>
